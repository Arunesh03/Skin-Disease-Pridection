{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define a dictionary to map class indices to disease names\n",
    "class_labels = {\n",
    "    0: 'Acne and Rosacea Photos',\n",
    "    1: 'Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions',\n",
    "    2: 'Atopic Dermatitis Photos',\n",
    "    3: 'Bullous Disease Photos',\n",
    "    4: 'Cellulitis Impetigo and other Bacterial Infections',\n",
    "    5: 'Eczema Photos',\n",
    "    6: 'Exanthems and Drug Eruptions',\n",
    "    7: 'Hair Loss Photos Alopecia and other Hair Diseases',\n",
    "    8: 'Herpes HPV and other STDs Photos',\n",
    "    9: 'Light Diseases and Disorders of Pigmentation',\n",
    "    10: 'Lupus and other Connective Tissue diseases',\n",
    "    11: 'Melanoma Skin Cancer Nevi and Moles',\n",
    "    12: 'Nail Fungus and other Nail Disease',\n",
    "    13: 'Poison Ivy Photos and other Contact Dermatitis',\n",
    "    14: 'Psoriasis pictures Lichen Planus and related diseases',\n",
    "    15: 'Scabies Lyme Disease and other Infestations and Bites',\n",
    "    16: 'Seborrheic Keratoses and other Benign Tumors',\n",
    "    17: 'Systemic Disease',\n",
    "    18: 'Tinea Ringworm Candidiasis and other Fungal Infections',\n",
    "    19: 'Urticaria Hives',\n",
    "    20: 'Vascular Tumors',\n",
    "    21: 'Vasculitis Photos',\n",
    "    22: 'Warts Molluscum and other Viral Infections'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (299, 299)  # InceptionV3 input size\n",
    "BATCH_SIZE = 128\n",
    "NUM_CLASSES = len(class_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,  # Normalize pixel values to [0, 1]\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15550 images belonging to 23 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'D:/skin dataset/train',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3931 images belonging to 23 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'D:/skin dataset/test',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 87s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# Create an InceptionV3 base model with pre-trained weights\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "121/121 [==============================] - 1532s 12s/step - loss: 2.8308 - accuracy: 0.1869 - val_loss: 2.5810 - val_accuracy: 0.2542\n",
      "Epoch 2/50\n",
      "121/121 [==============================] - 1249s 10s/step - loss: 2.5897 - accuracy: 0.2437 - val_loss: 2.4645 - val_accuracy: 0.2854\n",
      "Epoch 3/50\n",
      "121/121 [==============================] - 1201s 10s/step - loss: 2.4898 - accuracy: 0.2714 - val_loss: 2.4082 - val_accuracy: 0.3013\n",
      "Epoch 4/50\n",
      "121/121 [==============================] - 1156s 10s/step - loss: 2.4311 - accuracy: 0.2852 - val_loss: 2.3721 - val_accuracy: 0.3055\n",
      "Epoch 5/50\n",
      "121/121 [==============================] - 1195s 10s/step - loss: 2.3891 - accuracy: 0.2933 - val_loss: 2.3307 - val_accuracy: 0.3208\n",
      "Epoch 6/50\n",
      "121/121 [==============================] - 1207s 10s/step - loss: 2.3444 - accuracy: 0.3041 - val_loss: 2.3001 - val_accuracy: 0.3299\n",
      "Epoch 7/50\n",
      "121/121 [==============================] - 1222s 10s/step - loss: 2.3081 - accuracy: 0.3195 - val_loss: 2.2793 - val_accuracy: 0.3365\n",
      "Epoch 8/50\n",
      "121/121 [==============================] - 1089s 9s/step - loss: 2.2812 - accuracy: 0.3241 - val_loss: 2.2490 - val_accuracy: 0.3422\n",
      "Epoch 9/50\n",
      "121/121 [==============================] - 1187s 10s/step - loss: 2.2554 - accuracy: 0.3280 - val_loss: 2.2428 - val_accuracy: 0.3492\n",
      "Epoch 10/50\n",
      "121/121 [==============================] - 1149s 9s/step - loss: 2.2352 - accuracy: 0.3335 - val_loss: 2.2231 - val_accuracy: 0.3513\n",
      "Epoch 11/50\n",
      "121/121 [==============================] - 1133s 9s/step - loss: 2.2174 - accuracy: 0.3410 - val_loss: 2.2210 - val_accuracy: 0.3432\n",
      "Epoch 12/50\n",
      "121/121 [==============================] - 1143s 9s/step - loss: 2.1843 - accuracy: 0.3419 - val_loss: 2.2026 - val_accuracy: 0.3549\n",
      "Epoch 13/50\n",
      "121/121 [==============================] - 1140s 9s/step - loss: 2.1636 - accuracy: 0.3511 - val_loss: 2.1923 - val_accuracy: 0.3523\n",
      "Epoch 14/50\n",
      "121/121 [==============================] - 1145s 9s/step - loss: 2.1531 - accuracy: 0.3582 - val_loss: 2.1727 - val_accuracy: 0.3643\n",
      "Epoch 15/50\n",
      "121/121 [==============================] - 1143s 9s/step - loss: 2.1359 - accuracy: 0.3600 - val_loss: 2.1639 - val_accuracy: 0.3625\n",
      "Epoch 16/50\n",
      "121/121 [==============================] - 1140s 9s/step - loss: 2.1307 - accuracy: 0.3639 - val_loss: 2.1632 - val_accuracy: 0.3688\n",
      "Epoch 17/50\n",
      "121/121 [==============================] - 1143s 9s/step - loss: 2.1015 - accuracy: 0.3680 - val_loss: 2.1390 - val_accuracy: 0.3773\n",
      "Epoch 18/50\n",
      "121/121 [==============================] - 1144s 9s/step - loss: 2.0872 - accuracy: 0.3750 - val_loss: 2.1305 - val_accuracy: 0.3758\n",
      "Epoch 19/50\n",
      "121/121 [==============================] - 1140s 9s/step - loss: 2.0763 - accuracy: 0.3731 - val_loss: 2.1291 - val_accuracy: 0.3758\n",
      "Epoch 20/50\n",
      "121/121 [==============================] - 1143s 9s/step - loss: 2.0597 - accuracy: 0.3787 - val_loss: 2.1148 - val_accuracy: 0.3815\n",
      "Epoch 21/50\n",
      "121/121 [==============================] - 1132s 9s/step - loss: 2.0510 - accuracy: 0.3844 - val_loss: 2.1165 - val_accuracy: 0.3784\n",
      "Epoch 22/50\n",
      "121/121 [==============================] - 1144s 9s/step - loss: 2.0484 - accuracy: 0.3876 - val_loss: 2.1118 - val_accuracy: 0.3763\n",
      "Epoch 23/50\n",
      "121/121 [==============================] - 1145s 9s/step - loss: 2.0353 - accuracy: 0.3882 - val_loss: 2.1071 - val_accuracy: 0.3810\n",
      "Epoch 24/50\n",
      "121/121 [==============================] - 1142s 9s/step - loss: 2.0198 - accuracy: 0.3892 - val_loss: 2.0844 - val_accuracy: 0.3891\n",
      "Epoch 25/50\n",
      "121/121 [==============================] - 1143s 9s/step - loss: 2.0053 - accuracy: 0.3990 - val_loss: 2.0860 - val_accuracy: 0.3792\n",
      "Epoch 26/50\n",
      "121/121 [==============================] - 1145s 9s/step - loss: 1.9877 - accuracy: 0.4068 - val_loss: 2.0761 - val_accuracy: 0.3859\n",
      "Epoch 27/50\n",
      "121/121 [==============================] - 1234s 10s/step - loss: 1.9799 - accuracy: 0.3981 - val_loss: 2.0674 - val_accuracy: 0.3901\n",
      "Epoch 28/50\n",
      "121/121 [==============================] - 1255s 10s/step - loss: 1.9678 - accuracy: 0.4047 - val_loss: 2.0764 - val_accuracy: 0.3849\n",
      "Epoch 29/50\n",
      "121/121 [==============================] - 1170s 10s/step - loss: 1.9531 - accuracy: 0.4149 - val_loss: 2.0543 - val_accuracy: 0.3945\n",
      "Epoch 30/50\n",
      "121/121 [==============================] - 1157s 10s/step - loss: 1.9574 - accuracy: 0.4136 - val_loss: 2.0566 - val_accuracy: 0.3938\n",
      "Epoch 31/50\n",
      "121/121 [==============================] - 1058s 9s/step - loss: 1.9539 - accuracy: 0.4115 - val_loss: 2.0470 - val_accuracy: 0.3927\n",
      "Epoch 32/50\n",
      "121/121 [==============================] - 1034s 9s/step - loss: 1.9347 - accuracy: 0.4157 - val_loss: 2.0394 - val_accuracy: 0.3982\n",
      "Epoch 33/50\n",
      "121/121 [==============================] - 1044s 9s/step - loss: 1.9332 - accuracy: 0.4116 - val_loss: 2.0353 - val_accuracy: 0.4034\n",
      "Epoch 34/50\n",
      "121/121 [==============================] - 1051s 9s/step - loss: 1.9209 - accuracy: 0.4238 - val_loss: 2.0329 - val_accuracy: 0.3997\n",
      "Epoch 35/50\n",
      "121/121 [==============================] - 1051s 9s/step - loss: 1.9071 - accuracy: 0.4223 - val_loss: 2.0222 - val_accuracy: 0.4073\n",
      "Epoch 36/50\n",
      "121/121 [==============================] - 1036s 9s/step - loss: 1.8985 - accuracy: 0.4270 - val_loss: 2.0147 - val_accuracy: 0.4078\n",
      "Epoch 37/50\n",
      "121/121 [==============================] - 1025s 8s/step - loss: 1.9003 - accuracy: 0.4262 - val_loss: 2.0209 - val_accuracy: 0.4000\n",
      "Epoch 38/50\n",
      "121/121 [==============================] - 1062s 9s/step - loss: 1.8813 - accuracy: 0.4352 - val_loss: 2.0226 - val_accuracy: 0.3977\n",
      "Epoch 39/50\n",
      "121/121 [==============================] - 1153s 10s/step - loss: 1.8766 - accuracy: 0.4335 - val_loss: 2.0160 - val_accuracy: 0.4096\n",
      "Epoch 40/50\n",
      "121/121 [==============================] - 1133s 9s/step - loss: 1.8698 - accuracy: 0.4336 - val_loss: 2.0068 - val_accuracy: 0.4130\n",
      "Epoch 41/50\n",
      "121/121 [==============================] - 1225s 10s/step - loss: 1.8601 - accuracy: 0.4367 - val_loss: 2.0006 - val_accuracy: 0.4068\n",
      "Epoch 42/50\n",
      "121/121 [==============================] - 1226s 10s/step - loss: 1.8531 - accuracy: 0.4355 - val_loss: 1.9901 - val_accuracy: 0.4112\n",
      "Epoch 43/50\n",
      "121/121 [==============================] - 1039s 9s/step - loss: 1.8509 - accuracy: 0.4387 - val_loss: 1.9933 - val_accuracy: 0.4102\n",
      "Epoch 44/50\n",
      "121/121 [==============================] - 1003s 8s/step - loss: 1.8371 - accuracy: 0.4466 - val_loss: 1.9822 - val_accuracy: 0.4174\n",
      "Epoch 45/50\n",
      "121/121 [==============================] - 1003s 8s/step - loss: 1.8294 - accuracy: 0.4476 - val_loss: 1.9879 - val_accuracy: 0.4125\n",
      "Epoch 46/50\n",
      "121/121 [==============================] - 1005s 8s/step - loss: 1.8182 - accuracy: 0.4449 - val_loss: 1.9794 - val_accuracy: 0.4180\n",
      "Epoch 47/50\n",
      "121/121 [==============================] - 1066s 9s/step - loss: 1.8107 - accuracy: 0.4510 - val_loss: 1.9733 - val_accuracy: 0.4151\n",
      "Epoch 48/50\n",
      "121/121 [==============================] - 1063s 9s/step - loss: 1.8093 - accuracy: 0.4544 - val_loss: 1.9740 - val_accuracy: 0.4180\n",
      "Epoch 49/50\n",
      "121/121 [==============================] - 1097s 9s/step - loss: 1.8063 - accuracy: 0.4568 - val_loss: 1.9703 - val_accuracy: 0.4185\n",
      "Epoch 50/50\n",
      "121/121 [==============================] - 1093s 9s/step - loss: 1.7987 - accuracy: 0.4553 - val_loss: 1.9645 - val_accuracy: 0.4245\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 50\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // BATCH_SIZE,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 220s 7s/step - loss: 1.9688 - accuracy: 0.4246\n",
      "Test Loss: 1.9688286781311035\n",
      "Test Accuracy: 0.4245738983154297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bhava\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Save the model\n",
    "model.save('skin_disease_classifier_inceptionv3.h5')\n",
    "model.save('skin_disease_classifier_inceptionv3.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
