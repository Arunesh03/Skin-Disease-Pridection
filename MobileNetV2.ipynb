{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = {\n",
    "        0: 'Acne and Rosacea Photos',\n",
    "    1: 'Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions',\n",
    "    2: 'Atopic Dermatitis Photos',\n",
    "    3: 'Bullous Disease Photos',\n",
    "    4: 'Cellulitis Impetigo and other Bacterial Infections',\n",
    "    5: 'Eczema Photos',\n",
    "    6: 'Exanthems and Drug Eruptions',\n",
    "    7: 'Hair Loss Photos Alopecia and other Hair Diseases',\n",
    "    8: 'Herpes HPV and other STDs Photos',\n",
    "    9: 'Light Diseases and Disorders of Pigmentation',\n",
    "    10: 'Lupus and other Connective Tissue diseases',\n",
    "    11: 'Melanoma Skin Cancer Nevi and Moles',\n",
    "    12: 'Nail Fungus and other Nail Disease',\n",
    "    13: 'Poison Ivy Photos and other Contact Dermatitis',\n",
    "    14: 'Psoriasis pictures Lichen Planus and related diseases',\n",
    "    15: 'Scabies Lyme Disease and other Infestations and Bites',\n",
    "    16: 'Seborrheic Keratoses and other Benign Tumors',\n",
    "    17: 'Systemic Disease',\n",
    "    18: 'Tinea Ringworm Candidiasis and other Fungal Infections',\n",
    "    19: 'Urticaria Hives',\n",
    "    20: 'Vascular Tumors',\n",
    "    21: 'Vasculitis Photos',\n",
    "    22: 'Warts Molluscum and other Viral Infections'\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "IMAGE_SIZE = (224, 224)  # MobileNetV2 input size\n",
    "BATCH_SIZE = 64  # Experiment with batch size\n",
    "NUM_CLASSES = len(class_labels)  # The number of classes in your dataset\n",
    "\n",
    "# Data Augmentation and Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15557 images belonging to 23 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Data Augmentation and Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'D:/skin dataset/train',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4002 images belonging to 23 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'D:/skin dataset/test',\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MobileNetV2 base model with pre-trained weights\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom classification layers on top of the base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "243/243 [==============================] - 1681s 7s/step - loss: 2.8376 - accuracy: 0.1856 - val_loss: 2.5350 - val_accuracy: 0.2634\n",
      "Epoch 2/10\n",
      "243/243 [==============================] - 1654s 7s/step - loss: 2.5604 - accuracy: 0.2477 - val_loss: 2.4397 - val_accuracy: 0.2873\n",
      "Epoch 3/10\n",
      "243/243 [==============================] - 1710s 7s/step - loss: 2.4568 - accuracy: 0.2769 - val_loss: 2.3847 - val_accuracy: 0.2976\n",
      "Epoch 4/10\n",
      "243/243 [==============================] - 1782s 7s/step - loss: 2.3863 - accuracy: 0.2937 - val_loss: 2.3429 - val_accuracy: 0.3047\n",
      "Epoch 5/10\n",
      "243/243 [==============================] - 1594s 7s/step - loss: 2.3444 - accuracy: 0.3056 - val_loss: 2.3114 - val_accuracy: 0.3211\n",
      "Epoch 6/10\n",
      "243/243 [==============================] - 1585s 7s/step - loss: 2.2993 - accuracy: 0.3167 - val_loss: 2.2750 - val_accuracy: 0.3251\n",
      "Epoch 7/10\n",
      "243/243 [==============================] - 1515s 6s/step - loss: 2.2580 - accuracy: 0.3233 - val_loss: 2.2655 - val_accuracy: 0.3276\n",
      "Epoch 8/10\n",
      "243/243 [==============================] - 1427s 6s/step - loss: 2.2135 - accuracy: 0.3403 - val_loss: 2.2361 - val_accuracy: 0.3359\n",
      "Epoch 9/10\n",
      "243/243 [==============================] - 1295s 5s/step - loss: 2.1867 - accuracy: 0.3494 - val_loss: 2.2226 - val_accuracy: 0.3425\n",
      "Epoch 10/10\n",
      "243/243 [==============================] - 1528s 6s/step - loss: 2.1632 - accuracy: 0.3500 - val_loss: 2.2154 - val_accuracy: 0.3483\n",
      "63/63 [==============================] - 265s 4s/step - loss: 2.2167 - accuracy: 0.3476\n",
      "Test Loss: 2.216695785522461\n",
      "Test Accuracy: 0.34757620096206665\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 10  # Experiment with the number of epochs\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // BATCH_SIZE,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bhava\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('skin_disease_classifier_mobilenetv2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('skin_disease_classifier_mobilenetv2.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
